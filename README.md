# ğŸ” Multimodal AI Search Engine

A sophisticated image search engine that enables both text-to-image and image-to-image similarity search using state-of-the-art deep learning models. Built with CLIP (Contrastive Language-Image Pre-training) and FAISS for efficient vector search.

## ğŸŒŸ Features

- **ğŸ”¤ Text-to-Image Search**: Find images using natural language descriptions
- **ğŸ–¼ï¸ Image-to-Image Search**: Upload an image to find visually similar ones  
- **âš¡ Fast Search**: Sub-second query response times using FAISS indexing
- **ğŸ¯ High Accuracy**: Powered by OpenAI's CLIP-ViT-B-32 model
- **ğŸ¨ Modern UI**: Clean, responsive Gradio interface
- **ğŸš€ GPU Accelerated**: CUDA support for faster inference

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Text Query    â”‚    â”‚   Image Query    â”‚    â”‚   CLIP Model    â”‚
â”‚   "red car"     â”‚â”€â”€â”€â”€â–¶   [Image.jpg]    â”‚â”€â”€â”€â”€â–¶  ViT-B-32      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                         â”‚
                                                         â–¼
                                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                               â”‚   Embeddings    â”‚
                                               â”‚   512-dim       â”‚
                                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                         â”‚
                                                         â–¼
                                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                               â”‚  FAISS Index    â”‚
                                               â”‚ Cosine Similarityâ”‚
                                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                         â”‚
                                                         â–¼
                                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                               â”‚ Top-K Results   â”‚
                                               â”‚ + Scores        â”‚
                                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- CUDA-capable GPU (recommended, 8GB+ VRAM)
- 4GB+ RAM

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/aswnrj/multimodal-ai-search-engine.git
cd multimodal-search-engine
```

2. **Install dependencies**
```bash
pip install -r requirements.txt
```

3. **Download and prepare the dataset**
```bash
python download_images_hf.py
python embed_images_clip.py
python build_faiss_index.py
```

4. **Launch the application**
```bash
python app.py
```

The app will be available at `http://localhost:7860`

## ğŸ“Š Dataset

- **Source**: Caltech101 dataset via HuggingFace (`flwrlabs/caltech101`)
- **Size**: 500 randomly sampled images
- **Categories**: 101 different object classes
- **Format**: RGB images, various resolutions
- **Preprocessing**: Normalized for CLIP compatibility

## ğŸ”§ Technical Implementation

### Core Components

1. **Image Embedding** (`embed_images_clip.py`)
   - Loads images and converts to RGB
   - Generates 512-dim embeddings using CLIP-ViT-B-32
   - Applies L2 normalization for cosine similarity

2. **FAISS Indexing** (`build_faiss_index.py`)
   - Creates IndexFlatIP for inner product search
   - Optimized for normalized embeddings
   - Persistent storage for fast loading

3. **Search Interface** (`search_image_and_text.py`)
   - Unified search functions for text and image queries
   - Real-time embedding generation
   - Efficient similarity computation

4. **Web Interface** (`app.py`)
   - Modern Gradio-based UI
   - Dual-mode search (text/image)
   - Result visualization with similarity scores

### Key Algorithms

- **CLIP**: Contrastive learning between text and images
- **Vision Transformer**: Self-attention mechanism for image processing
- **Cosine Similarity**: Semantic similarity measurement
- **FAISS IndexFlatIP**: Exhaustive search with inner product

## ğŸ“ˆ Performance Metrics

| Metric | Value |
|--------|-------|
| Search Latency | <100ms |
| Embedding Dimension | 512 |
| Index Size | ~1MB (500 images) |
| Memory Usage | ~2GB (with model) |
| GPU Utilization | ~1GB VRAM |

## ğŸ› ï¸ Project Structure

```
multimodal-search-engine/
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ images/              # Downloaded images
â”‚   â”œâ”€â”€ image_embeddings.npy # Precomputed embeddings
â”‚   â”œâ”€â”€ image_filenames.npy  # Filename mappings
â”‚   â””â”€â”€ faiss_index.bin      # FAISS search index
â”œâ”€â”€ download_images_hf.py    # Dataset downloader
â”œâ”€â”€ embed_images_clip.py     # Embedding generator
â”œâ”€â”€ build_faiss_index.py     # Index builder
â”œâ”€â”€ search_image_and_text.py # Search utilities
â”œâ”€â”€ app.py                   # Gradio web interface
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ README.md               # Documentation
```

## ğŸ¯ Use Cases

- **E-commerce**: Product similarity search
- **Digital Asset Management**: Content organization
- **Research**: Dataset exploration and analysis  
- **Education**: Visual learning and discovery
- **Creative**: Inspiration and mood board creation

## ğŸ”® Future Enhancements

- [ ] Support for larger datasets (10K+ images)
- [ ] Multiple CLIP model variants comparison
- [ ] Advanced filtering options (category, color, etc.)
- [ ] Batch upload for multiple query images
- [ ] API endpoints for programmatic access
- [ ] Similarity threshold tuning
- [ ] Export search results functionality

## ğŸ“š Dependencies

### Core ML Libraries
- **PyTorch**: Deep learning framework
- **Sentence Transformers**: CLIP model interface
- **FAISS**: Vector similarity search
- **NumPy**: Numerical computations

### Data & UI
- **Pillow**: Image processing
- **Gradio**: Web interface
- **Datasets**: HuggingFace dataset loading
- **TQDM**: Progress tracking

## ğŸ† Academic Applications

This project demonstrates several key concepts valuable for AI/ML academic programs:

- **Multimodal Learning**: Cross-modal understanding between text and images
- **Vector Databases**: Efficient similarity search at scale
- **Transfer Learning**: Leveraging pre-trained models
- **UI/UX Design**: Making AI accessible through intuitive interfaces
- **System Architecture**: Building end-to-end ML pipelines

## ğŸ“– References

1. Radford, A., et al. "Learning Transferable Visual Representations from Natural Language Supervision." ICML 2021.
2. Johnson, J., Douze, M., JÃ©gou, H. "Billion-scale similarity search with GPUs." IEEE Transactions on Big Data 2019.
3. Fei-Fei, L., Fergus, R., Perona, P. "Learning generative visual models from few training examples." CVPR 2004.

## ğŸ“„ License

MIT License - feel free to use this project for educational and research purposes.

## ğŸ‘¨â€ğŸ’» Author

Aswin Raj Rajan

---
